{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE Exploratory Analysis\n",
    "\n",
    "Interactive analysis of R(D)-optimal initialization experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.linear_gaussian import LinearGaussianDataset\n",
    "from src.models.vqvae import LinearGaussianVQVAE\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = LinearGaussianDataset(\n",
    "    d=64,\n",
    "    k=8,\n",
    "    sigma_noise=0.1,\n",
    "    n_samples=10000,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "print(f\"\\nData variance: {dataset.X.var():.3f}\")\n",
    "print(f\"Latent variance (σ_z²): {dataset.sigma_z_squared:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "results_dir = '../results/idea_7_linear_gaussian'\n",
    "\n",
    "metrics = {}\n",
    "for method in ['uniform', 'kmeans', 'rd_gaussian']:\n",
    "    path = f\"{results_dir}/{method}/metrics.csv\"\n",
    "    metrics[method] = pd.read_csv(path)\n",
    "\n",
    "# Display summary\n",
    "for method, df in metrics.items():\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    print(f\"  Steps: {len(df)}\")\n",
    "    print(f\"  Initial Q.Err: {df['quantization_error'].iloc[0]:.6f}\")\n",
    "    print(f\"  Final Q.Err: {df['quantization_error'].iloc[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "colors = {'uniform': 'red', 'kmeans': 'blue', 'rd_gaussian': 'green'}\n",
    "\n",
    "for method, df in metrics.items():\n",
    "    axes[0, 0].plot(df['step'], df['quantization_error'], \n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "    axes[0, 1].plot(df['step'], df['perplexity'], \n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "    axes[1, 0].plot(df['step'], df['dead_codes'], \n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "    axes[1, 1].plot(df['step'], df['recon_loss'], \n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "\n",
    "axes[0, 0].set_title('Quantization Error')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_yscale('log')\n",
    "\n",
    "axes[0, 1].set_title('Perplexity')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 0].set_title('Dead Codes')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].set_title('Reconstruction Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare to Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute theoretical R(D) bound\n",
    "k = 8\n",
    "codebook_size = 256\n",
    "sigma_z_sq = dataset.sigma_z_squared\n",
    "\n",
    "R = np.log2(codebook_size) / k\n",
    "D_theory = k * sigma_z_sq * (2 ** (-2 * R))\n",
    "\n",
    "print(f\"\\nTheoretical Analysis:\")\n",
    "print(f\"  Rate R: {R:.3f} bits/dim\")\n",
    "print(f\"  σ_z²: {sigma_z_sq:.3f}\")\n",
    "print(f\"  Theoretical bound D*: {D_theory:.6f}\")\n",
    "\n",
    "print(f\"\\nInitial Distortion:\")\n",
    "for method, df in metrics.items():\n",
    "    init_dist = df['quantization_error'].iloc[0]\n",
    "    ratio = init_dist / D_theory\n",
    "    print(f\"  {method:12s}: {init_dist:.6f} ({ratio:.2f}× theory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Analysis Here\n",
    "\n",
    "Add custom analysis, plots, or experiments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
